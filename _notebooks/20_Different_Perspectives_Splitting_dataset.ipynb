{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08881b7b-a656-4ee9-ae42-ace451dbddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sm\n",
    "import src.data.prepare_data as prepdata\n",
    "import src.features.aggregation_helper as ha\n",
    "import src.features.annotation_aggregator as aa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.features.annotation_aggregator import (\n",
    "    DawidSkeneAggregator,\n",
    "    MaceAggregator,\n",
    "    MajorityVoteAggregator,\n",
    ")\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a00784-2692-4b33-991e-d78f4dea8dcb",
   "metadata": {},
   "source": [
    "## Wikipedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87c48d0-c141-414b-bfd9-80e3ba5406ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\n",
      "----------------------------------\n",
      "115864 comments\n",
      "4053 annotators\n",
      "2 classes: [0.0, 1.0]\n",
      "----------------------------------\n",
      "Running majority voting\n",
      "Completed majority_voting in 0:00:01.374915 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Wikipedia\"\n",
    "(\n",
    "    class_mapping,\n",
    "    gold_labels,\n",
    "    annotator_labels_wide,\n",
    "    annotator_labels_long,\n",
    ") = prepdata.get_annotator_and_gold_labels_Wikipedia()\n",
    "label = class_mapping.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eaeeb9-37b1-4f72-8ea4-0d9de555c691",
   "metadata": {},
   "source": [
    "## Getting the bias matrices of the annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5443574-0e59-4e09-bdc0-d95f583422b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_ids, annotator_bias_matrices = ha.get_bias_matrix_per_annotator(\n",
    "    annotator_labels_wide, gold_labels, [0.0, 1.0]\n",
    ")\n",
    "annotator_ids_2, annotator_bias_matrices_2 = ha.get_bias_matrix_per_annotator(\n",
    "    annotator_labels_wide, gold_labels, [0.0, 1.0], normalize=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790f24bd-95a4-4ebd-9e07-998df062b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform bias matrices of annotators so that it can be converted to a dataframe\n",
    "vec_length = annotator_bias_matrices.shape[1] * annotator_bias_matrices.shape[2]\n",
    "annotator_bias_matrices_flattend = annotator_bias_matrices.reshape(-1, vec_length)\n",
    "\n",
    "# Create dataframe\n",
    "df_annotator_characteristics = pd.DataFrame(\n",
    "    annotator_bias_matrices_flattend,\n",
    "    index=annotator_ids,\n",
    "    columns=[\"Reliability 1\", \"Pessimistic\", \"Optimistic\", \"Reliability 2\"],\n",
    ")\n",
    "df_annotator_characteristics = df_annotator_characteristics.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433549f8-35aa-4562-9f3a-88fa0399846d",
   "metadata": {},
   "source": [
    "## Group the annoators \n",
    "The grouping used in the paper is \"Group 1\". \"Group 2\" uses a different grouping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366b8e6d-4c67-4dc1-bb9e-b34c21874891",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_pessimistic = statistics.median(df_annotator_characteristics[\"Pessimistic\"])\n",
    "median_optimistic = statistics.median(df_annotator_characteristics[\"Optimistic\"])\n",
    "\n",
    "\n",
    "def group_by_qudrant(p, o):\n",
    "    if p < median_pessimistic and o < median_optimistic:\n",
    "        return 0\n",
    "    if p < median_pessimistic and o >= median_optimistic:\n",
    "        return 1\n",
    "    if p >= median_pessimistic and o < median_optimistic:\n",
    "        return 2\n",
    "    if p >= median_pessimistic and o >= median_optimistic:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def group_by_linear_function(p, o):\n",
    "    fact = 3\n",
    "    if p >= fact * o:\n",
    "        return 0\n",
    "    if o >= fact * p:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "\n",
    "df_annotator_characteristics[\"Group 1\"] = df_annotator_characteristics.apply(\n",
    "    lambda x: group_by_linear_function(x[\"Pessimistic\"], x[\"Optimistic\"]), axis=1\n",
    ")\n",
    "df_annotator_characteristics[\"Group 2\"] = df_annotator_characteristics.apply(\n",
    "    lambda x: group_by_qudrant(x[\"Pessimistic\"], x[\"Optimistic\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2636b4-b283-48cb-b5d5-0e5af45c6562",
   "metadata": {},
   "source": [
    "## Calculate the number of documents annotated by all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee1490f-2c66-4a62-b438-7e9c38e79832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments in groups:\n",
      "0 \t 1312 \t 93350\n",
      "1 \t 1033 \t 112221\n",
      "2 \t 1708 \t 115757\n",
      "Overlapping documents: 90019\n"
     ]
    }
   ],
   "source": [
    "groups = []\n",
    "group_labels = []\n",
    "group_type = \"Group 1\"\n",
    "for cluster in set(df_annotator_characteristics[group_type].to_list()):\n",
    "    ids_annotators = set(\n",
    "        df_annotator_characteristics[\n",
    "            df_annotator_characteristics[group_type] == cluster\n",
    "        ][\"index\"].to_list()\n",
    "    )\n",
    "    groups.append(ids_annotators)\n",
    "    group_labels.append(cluster)\n",
    "\n",
    "print(\"Number of comments in groups:\")\n",
    "overlapping_comments = set(annotator_labels_long[\"id\"].to_list())\n",
    "min_threshold = 1\n",
    "for i, cluster in enumerate(groups):\n",
    "    if len(cluster) < min_threshold:\n",
    "        continue\n",
    "    df_select = annotator_labels_long[annotator_labels_long[\"annotator\"].isin(cluster)]\n",
    "    overlapping_comments = overlapping_comments.intersection(\n",
    "        set(df_select[\"id\"].to_list())\n",
    "    )\n",
    "    print(\n",
    "        group_labels[i],\n",
    "        \"\\t\",\n",
    "        len(cluster),\n",
    "        \"\\t\",\n",
    "        len(list(set(df_select[\"id\"].to_list()))),\n",
    "    )\n",
    "print(\"Overlapping documents:\", len(overlapping_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6cd71b-54d1-433c-adf4-6c4c8a8d9cc9",
   "metadata": {},
   "source": [
    "## Calculate the labels for each annotator group\n",
    "The label of a group is based on the majority vote of the annotators that are in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e47cfb-0069-42d1-b38a-0a8032a753ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_labels(text_ids, annotator_ids, df):\n",
    "    df = df[df[\"id\"].isin(text_ids) & df[\"annotator\"].isin(annotator_ids)]\n",
    "    df = df.sort_values(by=[\"id\"])\n",
    "    mja = MajorityVoteAggregator()\n",
    "    mja.aggregate(df)\n",
    "    mja_gold_labels = mja.get_aggregation(kind=\"df\", return_text=False)\n",
    "    return mja_gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49971dc9-3d30-45e4-a356-9b964c53f351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "90019 comments\n",
      "1312 annotators\n",
      "2 classes: [0.0, 1.0]\n",
      "----------------------------------\n",
      "Running majority voting\n",
      "Completed majority_voting in 0:00:00.827969 seconds\n",
      "\n",
      "----------------------------------\n",
      "90019 comments\n",
      "1033 annotators\n",
      "2 classes: [0.0, 1.0]\n",
      "----------------------------------\n",
      "Running majority voting\n",
      "Completed majority_voting in 0:00:00.839944 seconds\n",
      "\n",
      "----------------------------------\n",
      "90019 comments\n",
      "1708 annotators\n",
      "2 classes: [0.0, 1.0]\n",
      "----------------------------------\n",
      "Running majority voting\n",
      "Completed majority_voting in 0:00:00.908655 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>0</td>\n",
       "      <td>`- This is not ``creative``.  Those are the di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>0</td>\n",
       "      <td>`   the term ``standard model`` is itself less...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89320</td>\n",
       "      <td>0</td>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93890</td>\n",
       "      <td>0</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102817</td>\n",
       "      <td>0</td>\n",
       "      <td>-  Important note for all sysops There is a b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  label                                               text  label_0  \\\n",
       "0   37675      0  `- This is not ``creative``.  Those are the di...        0   \n",
       "1   44816      0  `   the term ``standard model`` is itself less...        0   \n",
       "2   89320      0   Next, maybe you could work on being less cond...        0   \n",
       "3   93890      0               This page will need disambiguation.         0   \n",
       "4  102817      0   -  Important note for all sysops There is a b...        0   \n",
       "\n",
       "   label_1  label_2  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        1        0  \n",
       "3        0        0  \n",
       "4        0        0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_annotations = gold_labels[\n",
    "    gold_labels[\"id\"].isin(overlapping_comments)\n",
    "].sort_values(by=[\"id\"])\n",
    "biased_annotations = biased_annotations.astype({f\"label\": int})\n",
    "\n",
    "if dataset_name == \"Wikipedia\":\n",
    "    df_to_merge = annotator_labels_long.drop_duplicates(subset=[\"id\"])\n",
    "    biased_annotations = biased_annotations.merge(\n",
    "        df_to_merge[[\"id\", \"text\"]], left_on=\"id\", right_on=\"id\", how=\"left\"\n",
    "    )\n",
    "\n",
    "for group, group_label in zip(groups, group_labels):\n",
    "    # get biased annotations\n",
    "    biased_annotations[f\"label_{group_label}\"] = get_gold_labels(\n",
    "        overlapping_comments, group, annotator_labels_long\n",
    "    )[\"label\"].to_list()\n",
    "    # change type of added column\n",
    "    biased_annotations = biased_annotations.astype({f\"label_{group_label}\": int})\n",
    "\n",
    "    \n",
    "biased_annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9fdfa-d87d-48bf-bd21-a1ecf8b14dab",
   "metadata": {},
   "source": [
    "## Calculate the differences between the labels of the different groups (in percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8f8abb-10cc-4e38-a570-8dc44d7a0301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740325</td>\n",
       "      <td>0.857091</td>\n",
       "      <td>0.882751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_0</th>\n",
       "      <td>0.740325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759019</td>\n",
       "      <td>0.654110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_1</th>\n",
       "      <td>0.857091</td>\n",
       "      <td>0.759019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_2</th>\n",
       "      <td>0.882751</td>\n",
       "      <td>0.654110</td>\n",
       "      <td>0.760798</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label   label_0   label_1   label_2\n",
       "label    1.000000  0.740325  0.857091  0.882751\n",
       "label_0  0.740325  1.000000  0.759019  0.654110\n",
       "label_1  0.857091  0.759019  1.000000  0.760798\n",
       "label_2  0.882751  0.654110  0.760798  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"label\", \"label_0\", \"label_1\", \"label_2\"]\n",
    "results = []\n",
    "for lab_0 in labels:\n",
    "    row = []\n",
    "    for lab_1 in labels:\n",
    "        row.append(\n",
    "            sm.f1_score(\n",
    "                biased_annotations[lab_0].to_list(),\n",
    "                biased_annotations[lab_1].to_list(),\n",
    "                average=\"macro\",\n",
    "            )\n",
    "        )\n",
    "    results.append(row)\n",
    "\n",
    "pd.DataFrame(data=results, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736ed15-ac7d-42bf-86fa-7a93840c1be3",
   "metadata": {},
   "source": [
    "## Split data in train, validation, and test set and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4956c18d-1b1e-447d-bcd9-b76acd23789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_validation, df_test = train_test_split(\n",
    "    biased_annotations, test_size=0.2, shuffle=True, random_state=5\n",
    ")\n",
    "df_train, df_validation = train_test_split(df_train_validation, test_size=len(df_test))\n",
    "\n",
    "path_name = f\"{dataset_name}_{group_type}\".replace(\" \", \"_\")\n",
    "df_train.to_pickle(f\"../tmp/{path_name}_bias_train.pkl\")\n",
    "df_test.to_pickle(f\"../tmp/{path_name}_bias_test.pkl\")\n",
    "df_validation.to_pickle(f\"../tmp/{path_name}_bias_validation.pkl\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m68"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
